{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5150c-cb51-40bd-b4bf-d94c7dd99c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "\n",
    "# Extract IMDb Dataset\n",
    "def extract_imdb_dataset(tar_path, extract_to=\"./imdb_dataset\"):\n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"Dataset file '{tar_path}' not found.\")\n",
    "        print(\"Please download the IMDb dataset manually and place it in the specified path.\")\n",
    "        return None\n",
    "\n",
    "    if not os.path.exists(extract_to) or not os.listdir(extract_to):\n",
    "        print(\"Extracting IMDb dataset...\")\n",
    "        with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "            tar.extractall(path=extract_to)\n",
    "        print(\"Extraction complete.\")\n",
    "    else:\n",
    "        print(\"IMDb dataset already extracted.\")\n",
    "    return extract_to\n",
    "\n",
    "\n",
    "# Load IMDb Dataset\n",
    "def load_imdb_data(dataset_dir):\n",
    "    print(\"Loading data...\")\n",
    "    texts, labels = [], []\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        for sentiment in [\"pos\", \"neg\"]:\n",
    "            dir_path = os.path.join(dataset_dir, split, sentiment)\n",
    "            label = 1 if sentiment == \"pos\" else 0\n",
    "            for file in os.listdir(dir_path):\n",
    "                with open(os.path.join(dir_path, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                    texts.append(f.read())\n",
    "                    labels.append(label)\n",
    "    print(\"Data has been loaded.\")\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "# Tokenize Texts and Build Vocabulary\n",
    "def build_vocab(texts, tokenizer, special_tokens=[\"<PAD>\", \"<UNK>\"]):\n",
    "    print(\"Tokenizing data...\")\n",
    "    vocab = {token: idx for idx, token in enumerate(special_tokens)}\n",
    "    for text in texts:\n",
    "        tokens = tokenizer.tokenize(text.lower())\n",
    "        for token in tokens:\n",
    "            if token not in vocab:\n",
    "                vocab[token] = len(vocab)\n",
    "    print(\"Data has been tokenized and vocabulary has been built.\")\n",
    "    return vocab\n",
    "\n",
    "\n",
    "# Define a function to build the lexicon\n",
    "def build_lexicon_from_swn():\n",
    "    print(\"Building lexicon...\") \n",
    "    \n",
    "    # Function to ensure `sentiwordnet` and `wordnet` resources are downloaded\n",
    "    def ensure_resource_downloaded(resource_name):\n",
    "        try:\n",
    "            find(resource_name)\n",
    "            print(f\"Resource '{resource_name}' is already downloaded.\")\n",
    "        except LookupError:\n",
    "            print(f\"Resource '{resource_name}' not found. Downloading now...\")\n",
    "            nltk.download(resource_name)\n",
    "\n",
    "    ensure_resource_downloaded(\"sentiwordnet\")\n",
    "    ensure_resource_downloaded(\"wordnet\")\n",
    "    \n",
    "    lexicon = {}\n",
    "    for word in swn.all_senti_synsets():\n",
    "        sentiment_score = word.pos_score() - word.neg_score()\n",
    "        if word.synset.name().split('.')[0] not in lexicon:\n",
    "            lexicon[word.synset.name().split('.')[0]] = sentiment_score\n",
    "    print(\"Lexicon has been built.\")\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "# Define Preprocessing Functions\n",
    "def preprocess_text(text, vocab, max_len):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    token_indices = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
    "    token_indices = token_indices[:max_len] + [0] * (max_len - len(token_indices))\n",
    "    return token_indices\n",
    "\n",
    "def get_lexicon_features(text, lexicon, vocab, max_len):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    features = [lexicon.get(token, 0.0) for token in tokens]\n",
    "    features = features[:max_len] + [0.0] * (max_len - len(features))\n",
    "    return features\n",
    "\n",
    "\n",
    "# Define Dataset Class\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, lexicon, max_len=100):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.lexicon = lexicon\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        token_indices = preprocess_text(text, self.vocab, self.max_len)\n",
    "        lexicon_features = get_lexicon_features(text, self.lexicon, self.vocab, self.max_len)\n",
    "        return {\n",
    "            \"tokens\": torch.tensor(token_indices, dtype=torch.long),\n",
    "            \"lexicon_features\": torch.tensor(lexicon_features, dtype=torch.float),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb982a9-5ec9-4817-8ef0-e513c56993ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to IMDb dataset\n",
    "base_dir = \"/Users/sonnguyen/Desktop/Fall24/lign167/project/lign167/\"  # Directory of the script\n",
    "tar_path = os.path.join(base_dir, \"imdb_dataset/aclImdb_v1.tar.gz\")\n",
    "extracted_path = os.path.join(base_dir, \"imdb_dataset/aclImdb/aclImdb\")\n",
    "\n",
    "# Extract and load the dataset\n",
    "extract_imdb_dataset(tar_path, extracted_path)\n",
    "texts, labels = load_imdb_data(extracted_path)\n",
    "\n",
    "\n",
    "# Tokenize and build vocabulary\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "vocab = build_vocab(texts, tokenizer)\n",
    "\n",
    "\n",
    "# Build the lexicon\n",
    "lexicon = build_lexicon_from_swn()\n",
    "\n",
    "\n",
    "# Create the PyTorch Dataset\n",
    "dataset = SentimentDataset(texts, labels, vocab, lexicon, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77135845-d5ec-472a-95bb-08eba5f97573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'able': 0.125,\n",
       " 'unable': -0.75,\n",
       " 'abaxial': 0.0,\n",
       " 'adaxial': 0.0,\n",
       " 'acroscopic': 0.0,\n",
       " 'basiscopic': 0.0,\n",
       " 'abducent': 0.0,\n",
       " 'adducent': 0.0,\n",
       " 'nascent': 0.0,\n",
       " 'emergent': 0.0,\n",
       " 'dissilient': 0.25,\n",
       " 'parturient': 0.25,\n",
       " 'dying': 0.0,\n",
       " 'moribund': 0.0,\n",
       " 'last': 0.0,\n",
       " 'abridged': 0.0,\n",
       " 'cut': 0.0,\n",
       " 'half-length': 0.0,\n",
       " 'potted': 0.0,\n",
       " 'unabridged': 0.0,\n",
       " 'full-length': 0.5,\n",
       " 'absolute': 0.5,\n",
       " 'direct': 0.75,\n",
       " 'implicit': 0.0,\n",
       " 'infinite': 0.125,\n",
       " 'living': 0.375,\n",
       " 'relative': -0.25,\n",
       " 'relational': 0.0,\n",
       " 'absorbent': 0.0,\n",
       " 'absorbefacient': 0.375,\n",
       " 'assimilating': -0.75,\n",
       " 'hygroscopic': 0.0,\n",
       " 'receptive': -0.125,\n",
       " 'shock-absorbent': 0.0,\n",
       " 'spongy': 0.0,\n",
       " 'thirsty': 0.0,\n",
       " 'nonabsorbent': -0.5,\n",
       " 'repellent': -0.5,\n",
       " 'adsorbent': 0.0,\n",
       " 'chemisorptive': -0.25,\n",
       " 'nonadsorbent': -0.25,\n",
       " 'absorbable': 0.5,\n",
       " 'adsorbable': 0.25,\n",
       " 'abstemious': 0.0,\n",
       " 'abstinent': -0.625,\n",
       " 'ascetic': 0.25,\n",
       " 'gluttonous': 0.0,\n",
       " 'crapulous': 0.0,\n",
       " 'crapulent': -0.5,\n",
       " 'edacious': 0.0,\n",
       " 'greedy': 0.0,\n",
       " 'hoggish': -0.125,\n",
       " 'overgreedy': -0.25,\n",
       " 'abstract': 0.0,\n",
       " 'conceptional': 0.375,\n",
       " 'conceptual': 0.125,\n",
       " 'ideal': 0.0,\n",
       " 'ideological': 0.0,\n",
       " 'concrete': 0.375,\n",
       " 'objective': 0.0,\n",
       " 'real': 0.0,\n",
       " 'abundant': -0.25,\n",
       " 'abounding': -0.25,\n",
       " 'ample': 0.125,\n",
       " 'copious': 0.0,\n",
       " 'easy': -0.375,\n",
       " 'exuberant': -0.25,\n",
       " 'thick': -0.5,\n",
       " 'long': -0.25,\n",
       " 'overabundant': -0.375,\n",
       " 'plentiful': -0.25,\n",
       " 'rampant': 0.0,\n",
       " 'rank': -0.25,\n",
       " 'superabundant': -0.375,\n",
       " 'teeming': 0.0,\n",
       " 'torrential': -0.375,\n",
       " 'verdant': -0.375,\n",
       " 'scarce': -0.25,\n",
       " 'rare': -0.875,\n",
       " 'tight': -0.625,\n",
       " 'abused': -0.625,\n",
       " 'battered': -0.75,\n",
       " 'unabused': 0.125,\n",
       " 'acceptable': 0.625,\n",
       " 'bankable': 0.25,\n",
       " 'unexceptionable': -0.375,\n",
       " 'unobjectionable': -0.5,\n",
       " 'unacceptable': -0.25,\n",
       " 'exceptionable': -0.375,\n",
       " 'accessible': 0.625,\n",
       " 'approachable': 0.375,\n",
       " 'come-at-able': 0.625,\n",
       " 'handy': 0.0,\n",
       " 'inaccessible': 0.375,\n",
       " 'outback': 0.125,\n",
       " 'pathless': -0.125,\n",
       " 'unapproachable': 0.0,\n",
       " 'un-come-at-able': -0.625,\n",
       " 'accommodating': 0.5,\n",
       " 'complaisant': 0.75,\n",
       " 'unaccommodating': 0.0,\n",
       " 'disobliging': -0.125,\n",
       " 'accurate': 0.5,\n",
       " 'close': 0.625,\n",
       " 'dead-on': 0.375,\n",
       " 'high-fidelity': 0.375,\n",
       " 'surgical': 0.5,\n",
       " 'straight': 0.0,\n",
       " 'true': 0.125,\n",
       " 'veracious': 0.875,\n",
       " 'inaccurate': -0.5,\n",
       " 'away': 0.0,\n",
       " 'faulty': -0.625,\n",
       " 'unfaithful': -0.5,\n",
       " 'wide': -0.625,\n",
       " 'accustomed': 0.125,\n",
       " 'used_to': -0.375,\n",
       " 'unaccustomed': -0.75,\n",
       " 'new': -0.125,\n",
       " 'unused': -0.125,\n",
       " 'acidic': -0.125,\n",
       " 'acid': -0.375,\n",
       " 'acid-forming': -0.5,\n",
       " 'alkaline': 0.0,\n",
       " 'alkalescent': -0.25,\n",
       " 'basic': 0.25,\n",
       " 'base-forming': 0.0,\n",
       " 'saltlike': 0.125,\n",
       " 'amphoteric': 0.5,\n",
       " 'acid-loving': -0.25,\n",
       " 'acidophilic': 0.0,\n",
       " 'alkaline-loving': -0.25,\n",
       " 'acknowledged': 0.125,\n",
       " 'accepted': 0.5,\n",
       " 'self-confessed': -0.125,\n",
       " 'assumptive': 0.25,\n",
       " 'declarable': 0.375,\n",
       " 'given': 0.0,\n",
       " 'putative': 0.125,\n",
       " 'unacknowledged': -0.625,\n",
       " 'unappreciated': -0.375,\n",
       " 'unavowed': 0.25,\n",
       " 'unconfessed': -0.375,\n",
       " 'unrecognized': -0.5,\n",
       " 'acquisitive': 0.0,\n",
       " 'accumulative': 0.375,\n",
       " 'avaricious': 0.0,\n",
       " 'possessive': 0.0,\n",
       " 'plundering': 0.0,\n",
       " 'predaceous': 0.0,\n",
       " 'rapacious': -0.25,\n",
       " 'sordid': -0.5,\n",
       " 'unacquisitive': -0.5,\n",
       " 'acropetal': 0.0,\n",
       " 'basipetal': 0.0,\n",
       " 'active': 0.375,\n",
       " 'about': 0.0,\n",
       " 'acrobatic': 0.375,\n",
       " 'agile': 0.0,\n",
       " 'hot': 0.5,\n",
       " 'hyperactive': 0.25,\n",
       " 'on_the_go': 0.125,\n",
       " 'sporty': 0.25,\n",
       " 'inactive': -0.125,\n",
       " 'desk-bound': 0.125,\n",
       " 'abeyant': -0.125,\n",
       " 'hypoactive': -0.625,\n",
       " 'inert': 0.125,\n",
       " 'sedentary': 0.125,\n",
       " 'activated': -0.125,\n",
       " 'off': -0.625,\n",
       " 'retired': -0.625,\n",
       " 'brisk': 0.125,\n",
       " 'bustling': 0.5,\n",
       " 'busy': 0.125,\n",
       " 'going': -0.5,\n",
       " 'open': 0.0,\n",
       " 'springy': -0.25,\n",
       " 'dark': 0.0,\n",
       " 'dead': 0.25,\n",
       " 'dull': -0.5,\n",
       " 'idle': -0.5,\n",
       " 'strikebound': 0.0,\n",
       " 'progressive': -0.25,\n",
       " 'dead-end': 0.0,\n",
       " 'flat': 0.0,\n",
       " 'indolent': 0.0,\n",
       " 'latent': -0.125,\n",
       " 'quiescent': -0.625,\n",
       " 'activist': 0.0,\n",
       " 'hands-on': 0.0,\n",
       " 'proactive': 0.0,\n",
       " 'passive': 0.125,\n",
       " 'hands-off': -0.625,\n",
       " 'resistless': -0.75,\n",
       " 'eruptive': -0.375,\n",
       " 'dormant': 0.0,\n",
       " 'extinct': 0.0,\n",
       " 'alive': 0.5,\n",
       " 'stative': 0.0,\n",
       " 'counteractive': -0.5,\n",
       " 'surface-active': 0.0,\n",
       " 'quiet': -0.5,\n",
       " 'actual': -0.375,\n",
       " 'effective': 0.5,\n",
       " 'potential': -0.25,\n",
       " 'acute': -0.5,\n",
       " 'subacute': 0.0,\n",
       " 'chronic': -0.375,\n",
       " 'degenerative': -0.375,\n",
       " 'virulent': 0.5,\n",
       " 'highly_infective': -0.25,\n",
       " 'deadly': -0.125,\n",
       " 'avirulent': -0.875,\n",
       " 'adaptive': 0.25,\n",
       " 'accommodative': 0.5,\n",
       " 'adaptational': 0.0,\n",
       " 'adjustive': 0.5,\n",
       " 'maladaptive': 0.125,\n",
       " 'dysfunctional': 0.0,\n",
       " 'maladjustive': 0.125,\n",
       " 'addicted': 0.0,\n",
       " 'alcoholic': 0.0,\n",
       " 'dependent': 0.0,\n",
       " 'unaddicted': -0.125,\n",
       " 'clean': 0.5,\n",
       " 'addictive': -0.625,\n",
       " 'nonaddictive': -0.25,\n",
       " 'additive': -0.375,\n",
       " 'addable': 0.5,\n",
       " 'extra': 0.0,\n",
       " 'complemental': 0.0,\n",
       " 'incremental': 0.0,\n",
       " 'intercalary': 0.0,\n",
       " 'summational': 0.0,\n",
       " 'supplementary': 0.0,\n",
       " 'subtractive': 0.25,\n",
       " 'ablative': 0.625,\n",
       " 'reductive': -0.625,\n",
       " 'addressed': 0.125,\n",
       " 'self-addressed': 0.0,\n",
       " 'unaddressed': -0.125,\n",
       " 'adequate': 0.0,\n",
       " 'adequate_to': 0.125,\n",
       " 'competent': 0.25,\n",
       " 'inadequate': -0.5,\n",
       " 'deficient': -0.625,\n",
       " 'incapable': -0.25,\n",
       " 'short-handed': -0.75,\n",
       " 'adhesive': -0.25,\n",
       " 'adherent': 0.0,\n",
       " 'agglutinate': 0.0,\n",
       " 'bondable': 0.25,\n",
       " 'coherent': 0.0,\n",
       " 'cohesive': -0.5,\n",
       " 'gluey': 0.0,\n",
       " 'gooey': 0.0,\n",
       " 'gum-like': 0.0,\n",
       " 'gummed': -0.25,\n",
       " 'pitchy': 0.0,\n",
       " 'self-sealing': -0.5,\n",
       " 'stick-on': -0.5,\n",
       " 'sticky': 0.0,\n",
       " 'nonadhesive': -0.75,\n",
       " 'nonglutinous': -0.625,\n",
       " 'nonresinous': -0.5,\n",
       " 'ungummed': -0.75,\n",
       " 'adjective': 0.0,\n",
       " 'substantive': 0.125,\n",
       " 'adoptable': 0.75,\n",
       " 'unadoptable': 0.0,\n",
       " 'adorned': 0.375,\n",
       " 'beady': -0.375,\n",
       " 'bedaubed': -0.5,\n",
       " 'bespectacled': -0.25,\n",
       " 'brocaded': 0.0,\n",
       " 'buttony': -0.125,\n",
       " 'carbuncled': 0.0,\n",
       " 'champleve': 0.0,\n",
       " 'clinquant': 0.0,\n",
       " 'crested': -0.25,\n",
       " 'crocketed': 0.0,\n",
       " 'feathery': -0.125,\n",
       " 'frilled': -0.125,\n",
       " 'fringed': -0.125,\n",
       " 'gilt-edged': 0.125,\n",
       " 'inflamed': -0.125,\n",
       " 'inlaid': -0.125,\n",
       " 'inwrought': 0.0,\n",
       " 'tessellated': 0.0,\n",
       " 'mounted': -0.25,\n",
       " 'paneled': -0.125,\n",
       " 'studded': -0.375,\n",
       " 'tapestried': -0.125,\n",
       " 'tasseled': -0.125,\n",
       " 'tricked-out': -0.125,\n",
       " 'tufted': -0.125,\n",
       " 'unadorned': -0.375,\n",
       " 'plain': -0.125,\n",
       " 'untufted': 0.0,\n",
       " 'cholinergic': 0.0,\n",
       " 'anticholinergic': 0.0,\n",
       " 'adroit': 0.25,\n",
       " 'clever': 0.625,\n",
       " 'coordinated': 0.0,\n",
       " 'deft': 0.0,\n",
       " 'light-fingered': 0.0,\n",
       " 'quick-witted': 0.5,\n",
       " 'maladroit': -0.125,\n",
       " 'bumbling': -0.625,\n",
       " 'inept': 0.375,\n",
       " 'uncoordinated': -0.25,\n",
       " 'unmechanical': -0.25,\n",
       " 'advantageous': 0.625,\n",
       " 'beneficial': 0.625,\n",
       " 'plus': 0.75,\n",
       " 'discriminatory': -0.125,\n",
       " 'disadvantageous': 0.5,\n",
       " 'minus': -0.875,\n",
       " 'adventurous': 0.375,\n",
       " 'audacious': 0.25,\n",
       " 'sporting': 0.0,\n",
       " 'swaggering': 0.125,\n",
       " 'unadventurous': -0.125,\n",
       " 'safe': 0.0,\n",
       " 'advisable': 0.625,\n",
       " 'better': 0.75,\n",
       " 'well': 0.625,\n",
       " 'inadvisable': -0.5,\n",
       " 'well-advised': 0.5,\n",
       " 'considered': 0.0,\n",
       " 'ill-advised': -0.125,\n",
       " 'aerobic': 0.0,\n",
       " 'aerobiotic': 0.0,\n",
       " 'oxidative': 0.0,\n",
       " 'anaerobic': -0.375,\n",
       " 'aesthetic': 0.625,\n",
       " 'artistic': 0.625,\n",
       " 'cosmetic': 0.0,\n",
       " 'painterly': 0.25,\n",
       " 'sensuous': 0.25,\n",
       " 'inaesthetic': 0.0,\n",
       " 'inartistic': -0.375,\n",
       " 'affected': 0.375,\n",
       " 'impressed': 0.0,\n",
       " 'smitten': -0.375,\n",
       " 'stage-struck': 0.125,\n",
       " 'subject': -0.625,\n",
       " 'taken': -0.375,\n",
       " 'wonder-struck': -0.5,\n",
       " 'unaffected': 0.0,\n",
       " 'immune': -0.625,\n",
       " 'superior': 0.125,\n",
       " 'unimpressed': -0.625,\n",
       " 'uninfluenced': -0.375,\n",
       " 'agonistic': 0.0,\n",
       " 'artificial': -0.25,\n",
       " 'constrained': -0.5,\n",
       " 'elocutionary': -0.25,\n",
       " 'mannered': -0.375,\n",
       " 'plummy': 0.125,\n",
       " 'lifelike': 0.25,\n",
       " 'unmannered': -0.375,\n",
       " 'unselfconscious': 0.0,\n",
       " 'unstilted': 0.0,\n",
       " 'affirmative': 0.5,\n",
       " 'assentient': 0.25,\n",
       " 'negative': -0.75,\n",
       " 'dissentient': -0.625,\n",
       " 'acceptive': 0.125,\n",
       " 'accepting': 0.25,\n",
       " 'rejective': -0.375,\n",
       " 'dismissive': -0.75,\n",
       " 'repudiative': 0.0,\n",
       " 'afloat': 0.0,\n",
       " 'adrift': 0.0,\n",
       " 'floating': 0.0,\n",
       " 'waterborne': 0.0,\n",
       " 'aground': 0.0,\n",
       " 'afraid': -0.5,\n",
       " 'acrophobic': -0.75,\n",
       " 'afeard': -0.125,\n",
       " 'aghast': 0.25,\n",
       " 'agoraphobic': -0.75,\n",
       " 'alarmed': -0.625,\n",
       " 'algophobic': -0.875,\n",
       " 'apprehensive': -0.5,\n",
       " 'hangdog': -0.125,\n",
       " 'claustrophobic': -0.75,\n",
       " 'fearful': -0.25,\n",
       " 'frightened': -0.125,\n",
       " 'horrified': -0.25,\n",
       " 'hunted': 0.5,\n",
       " 'hydrophobic': -0.75,\n",
       " 'mysophobic': -0.75,\n",
       " 'panicky': 0.0,\n",
       " 'numb': -0.75,\n",
       " 'shitless': -0.375,\n",
       " 'terror-stricken': -0.5,\n",
       " 'triskaidekaphobic': -0.625,\n",
       " 'unnerved': -0.625,\n",
       " 'white-lipped': 0.125,\n",
       " 'xenophobic': -0.75,\n",
       " 'unafraid': 0.125,\n",
       " 'unapprehensive': -0.625,\n",
       " 'unblinking': -0.125,\n",
       " 'unfrightened': 0.375,\n",
       " 'aggressive': 0.5,\n",
       " 'battleful': 0.5,\n",
       " 'competitive': 0.375,\n",
       " 'hard-hitting': 0.0,\n",
       " 'hostile': 0.0,\n",
       " 'in-your-face': 0.25,\n",
       " 'obstreperous': -0.125,\n",
       " 'predatory': 0.0,\n",
       " 'pugnacious': 0.25,\n",
       " 'scrappy': 0.25,\n",
       " 'truculent': -0.25,\n",
       " 'unaggressive': -0.625,\n",
       " 'low-pressure': -0.25,\n",
       " 'agitated': -0.5,\n",
       " 'aroused': -0.25,\n",
       " 'distraught': -0.125,\n",
       " 'jolted': -0.5,\n",
       " 'feverish': 0.0,\n",
       " 'frantic': -0.25,\n",
       " 'hysterical': -0.5,\n",
       " 'psychedelic': -0.5,\n",
       " 'wild-eyed': 0.0,\n",
       " 'unagitated': -0.5,\n",
       " 'churning': 0.0,\n",
       " 'rippled': 0.0,\n",
       " 'seething': 0.0,\n",
       " 'stirred': 0.0,\n",
       " 'nonturbulent': -0.25,\n",
       " 'unstirred': 0.25,\n",
       " 'agreeable': 0.5,\n",
       " 'disagreeable': -0.75,\n",
       " 'annoying': -0.5,\n",
       " 'harsh': -0.334,\n",
       " 'nerve-racking': -0.625,\n",
       " 'unsweet': -0.625,\n",
       " 'air-to-surface': 0.0,\n",
       " 'air-to-air': 0.0,\n",
       " 'surface-to-air': 0.0,\n",
       " 'alert': 0.5,\n",
       " 'argus-eyed': 0.375,\n",
       " 'fly': -0.5,\n",
       " 'heads-up': 0.5,\n",
       " 'lidless': -0.25,\n",
       " 'unalert': -0.25,\n",
       " 'algorithmic': 0.0,\n",
       " 'recursive': 0.0,\n",
       " 'heuristic': 0.0,\n",
       " 'trial-and-error': 0.0,\n",
       " 'alienable': 0.0,\n",
       " 'appropriable': 0.0,\n",
       " 'assignable': 0.125,\n",
       " 'inalienable': -0.25,\n",
       " 'non-negotiable': 0.5,\n",
       " 'nontransferable': -0.375,\n",
       " 'liveborn': 0.25,\n",
       " 'viable': 0.5,\n",
       " 'vital': 0.0,\n",
       " 'asleep': -0.5,\n",
       " 'assassinated': 0.0,\n",
       " 'bloodless': -0.5,\n",
       " 'brain_dead': 0.0,\n",
       " 'breathless': -0.75,\n",
       " 'cold': -0.375,\n",
       " 'd': 0.0,\n",
       " 'deathlike': -0.375,\n",
       " 'defunct': 0.0,\n",
       " 'doomed': -0.375,\n",
       " 'executed': 0.0,\n",
       " 'fallen': -0.25,\n",
       " 'late': 0.125,\n",
       " 'lifeless': -0.5,\n",
       " 'murdered': 0.0,\n",
       " 'nonviable': -0.625,\n",
       " 'slain': 0.0,\n",
       " 'stillborn': -0.25,\n",
       " 'stone-dead': -0.375,\n",
       " 'apocrine': 0.0,\n",
       " 'eccrine': 0.25,\n",
       " 'artesian': 0.0,\n",
       " 'subartesian': -0.125,\n",
       " 'live': 0.5,\n",
       " 'in_play': 0.0,\n",
       " 'out_of_play': 0.0,\n",
       " 'alphabetic': 0.0,\n",
       " 'abecedarian': 0.0,\n",
       " 'alphabetized': 0.0,\n",
       " 'analphabetic': -0.125,\n",
       " 'altricial': 0.0,\n",
       " 'precocial': 0.25,\n",
       " 'altruistic': 0.875,\n",
       " 'egoistic': 0.375,\n",
       " 'self-absorbed': 0.5,\n",
       " 'ambiguous': 0.125,\n",
       " 'double-barreled': 0.5,\n",
       " 'double-edged': 0.0,\n",
       " 'enigmatic': 0.125,\n",
       " 'left-handed': 0.0,\n",
       " 'multivalent': 0.375,\n",
       " 'polysemous': 0.0,\n",
       " 'uncertain': 0.0,\n",
       " 'unambiguous': 0.375,\n",
       " 'monosemous': 0.125,\n",
       " 'ambitious': 0.375,\n",
       " 'pushful': 0.625,\n",
       " 'aspirant': 0.5,\n",
       " 'compulsive': 0.375,\n",
       " 'manque': 0.25,\n",
       " 'overambitious': 0.125,\n",
       " 'unambitious': 0.5,\n",
       " 'shiftless': -0.25,\n",
       " 'ametropic': -0.25,\n",
       " 'emmetropic': 0.0,\n",
       " 'full': 0.0,\n",
       " 'generous': 0.25,\n",
       " 'meager': -0.625,\n",
       " 'bare': -0.5,\n",
       " 'exiguous': -0.5,\n",
       " 'hand-to-mouth': -0.5,\n",
       " 'hardscrabble': -0.375,\n",
       " 'measly': 0.0,\n",
       " 'anabolic': 0.5,\n",
       " 'constructive-metabolic': 0.0,\n",
       " 'catabolic': -0.75,\n",
       " 'destructive-metabolic': 0.0,\n",
       " 'anaclinal': 0.0,\n",
       " 'cataclinal': 0.0,\n",
       " 'anastigmatic': -0.25,\n",
       " 'astigmatic': 0.0,\n",
       " 'anticlinal': 0.0,\n",
       " 'synclinal': 0.0,\n",
       " 'anadromous': 0.0,\n",
       " 'catadromous': 0.0,\n",
       " 'diadromous': 0.0,\n",
       " 'anabatic': 0.0,\n",
       " 'katabatic': 0.0,\n",
       " 'anal': 0.0,\n",
       " 'oral': 0.0,\n",
       " 'analogue': 0.0,\n",
       " 'digital': 0.0,\n",
       " 'analytic': 0.125,\n",
       " 'synthetic': 0.0,\n",
       " 'isolating': 0.0,\n",
       " 'agglutinative': 0.0,\n",
       " 'inflectional': 0.0,\n",
       " 'derivational': -0.25,\n",
       " 'apocarpous': 0.0,\n",
       " 'syncarpous': 0.0,\n",
       " 'angry': 0.0,\n",
       " 'aggravated': -0.5,\n",
       " 'angered': 0.0,\n",
       " 'black': -0.375,\n",
       " 'choleric': -0.5,\n",
       " 'hot_under_the_collar': 0.0,\n",
       " 'huffy': 0.125,\n",
       " 'indignant': -0.75,\n",
       " 'irate': -0.375,\n",
       " 'livid': 0.125,\n",
       " 'smoldering': 0.25,\n",
       " 'wrathful': -0.25,\n",
       " 'unangry': -0.125,\n",
       " 'resentful': -0.875,\n",
       " 'acrimonious': 0.25,\n",
       " 'rancorous': 0.125,\n",
       " 'unresentful': -0.5,\n",
       " 'unbitter': -0.75,\n",
       " 'sentient': -0.25,\n",
       " 'sensate': -0.125,\n",
       " 'insentient': -0.375,\n",
       " 'unfeeling': -0.25,\n",
       " 'animate': 0.0,\n",
       " 'inanimate': -0.75,\n",
       " 'nonconscious': 0.0,\n",
       " 'animated': 0.375,\n",
       " 'enlivened': 0.375,\n",
       " 'full_of_life': 0.125,\n",
       " 'reanimated': 0.375,\n",
       " 'unanimated': -0.125,\n",
       " 'wan': -0.25,\n",
       " 'perked_up': 0.875,\n",
       " 'unenlivened': -0.625,\n",
       " 'anonymous': -0.5,\n",
       " 'nameless': 0.0,\n",
       " 'onymous': 0.0,\n",
       " 'binomial': 0.0,\n",
       " 'pseudonymous': 0.0,\n",
       " 'antemortem': 0.0,\n",
       " 'postmortem': -0.125,\n",
       " 'antecedent': 0.0,\n",
       " 'anterior': 0.0,\n",
       " 'anticipatory': 0.25,\n",
       " 'preexistent': -0.375,\n",
       " 'subsequent': 0.0,\n",
       " 'attendant': 0.0,\n",
       " 'later': 0.0,\n",
       " 'antrorse': 0.0,\n",
       " 'retrorse': 0.0,\n",
       " 'decurved': -0.125,\n",
       " 'aquatic': 0.0,\n",
       " 'marine': 0.0,\n",
       " 'semiaquatic': 0.0,\n",
       " 'subaqueous': 0.0,\n",
       " 'terrestrial': 0.0,\n",
       " 'onshore': 0.0,\n",
       " 'overland': 0.0,\n",
       " 'amphibious': 0.0,\n",
       " 'amphibiotic': 0.0,\n",
       " 'preceding': -0.125,\n",
       " 'above': -0.125,\n",
       " 'above-mentioned': -0.125,\n",
       " 'foregoing': 0.0,\n",
       " 'introductory': 0.0,\n",
       " 'precedent': 0.0,\n",
       " 'premedical': 0.0,\n",
       " 'preparatory': 0.0,\n",
       " 'previous': 0.0,\n",
       " 'succeeding': 0.0,\n",
       " 'back-to-back': -0.375,\n",
       " 'ensuing': 0.0,\n",
       " 'following': 0.0,\n",
       " 'in_line': 0.0,\n",
       " 'precedented': 0.375,\n",
       " 'unprecedented': 0.0,\n",
       " 'prehensile': 0.0,\n",
       " 'nonprehensile': -0.125,\n",
       " 'prenatal': -0.125,\n",
       " 'perinatal': 0.0,\n",
       " 'postnatal': -0.125,\n",
       " 'preprandial': 0.0,\n",
       " 'postprandial': 0.0,\n",
       " 'prewar': 0.0,\n",
       " 'postwar': 0.0,\n",
       " 'retrograde': -0.125,\n",
       " 'anterograde': -0.125,\n",
       " 'antemeridian': 0.0,\n",
       " 'ante_meridiem': 0.0,\n",
       " 'postmeridian': 0.0,\n",
       " 'post_meridiem': 0.0,\n",
       " 'frontal': 0.0,\n",
       " 'prefrontal': 0.0,\n",
       " 'posterior': 0.0,\n",
       " 'back': 0.0,\n",
       " 'caudal': 0.0,\n",
       " 'retral': 0.0,\n",
       " 'dorsal': 0.0,\n",
       " 'ventral': 0.0,\n",
       " 'dorsoventral': 0.0,\n",
       " 'appealable': 0.5,\n",
       " 'unappealable': -0.5,\n",
       " 'appendaged': 0.0,\n",
       " 'unappendaged': -0.625,\n",
       " 'appetizing': 0.25,\n",
       " 'mouth-watering': 0.375,\n",
       " 'unappetizing': -0.75,\n",
       " 'offish': -0.5,\n",
       " 'appropriate': 0.0,\n",
       " 'befitting': 0.0,\n",
       " 'grade-appropriate': 0.0,\n",
       " 'pat': 0.5,\n",
       " 'proper': 0.0,\n",
       " 'inappropriate': -0.625,\n",
       " 'unbefitting': -0.625,\n",
       " 'improper': -0.875,\n",
       " 'due': 0.0,\n",
       " 'callable': 0.0,\n",
       " 'collect': 0.0,\n",
       " 'collectible': 0.0,\n",
       " 'delinquent': -0.25,\n",
       " 'receivable': 0.0,\n",
       " 'out-of-pocket': 0.0,\n",
       " 'repayable': 0.0,\n",
       " 'undue': -0.125,\n",
       " 'apropos': 0.375,\n",
       " 'apposite': 0.125,\n",
       " 'malapropos': -0.5,\n",
       " 'inapposite': -0.75,\n",
       " 'a_priori': 0.25,\n",
       " 'a_posteriori': 0.125,\n",
       " 'apteral': -0.5,\n",
       " 'amphiprostylar': 0.375,\n",
       " 'prostyle': 0.375,\n",
       " 'peripteral': 0.0,\n",
       " 'monopteral': 0.0,\n",
       " 'peristylar': 0.0,\n",
       " 'arbitrable': 0.0,\n",
       " 'nonarbitrable': -0.625,\n",
       " 'columned': 0.125,\n",
       " 'amphistylar': 0.0,\n",
       " 'columnar': 0.125,\n",
       " 'columniform': 0.0,\n",
       " 'colonnaded': 0.125,\n",
       " 'pillared': 0.125,\n",
       " 'noncolumned': -0.5,\n",
       " 'astylar': -0.25,\n",
       " 'unpillared': -0.125,\n",
       " 'arboreal': 0.0,\n",
       " 'nonarboreal': -0.625,\n",
       " 'arenaceous': -0.125,\n",
       " 'argillaceous': -0.125,\n",
       " 'armed': 0.125,\n",
       " 'equipped': 0.0,\n",
       " 'light-armed': 0.0,\n",
       " 'militarized': 0.0,\n",
       " 'unarmed': -0.5,\n",
       " 'barehanded': 0.125,\n",
       " 'defenseless': -0.125,\n",
       " 'weaponless': 0.0,\n",
       " 'armored': -0.125,\n",
       " 'armor-clad': -0.375,\n",
       " 'bony-plated': -0.5,\n",
       " 'bulletproof': 0.125,\n",
       " 'lightly_armored': 0.0,\n",
       " 'mail-cheeked': 0.0,\n",
       " 'mail-clad': -0.125,\n",
       " 'scaled': 0.0,\n",
       " 'unarmored': 0.0,\n",
       " 'barbed': -0.375,\n",
       " 'bristlelike': 0.0,\n",
       " 'brushlike': -0.125,\n",
       " 'thistlelike': 0.0,\n",
       " 'clawed': -0.25,\n",
       " 'thornless': -0.25,\n",
       " 'armlike': -0.125,\n",
       " 'brachiate': 0.0,\n",
       " 'long-armed': 0.0,\n",
       " 'one-armed': 0.0,\n",
       " 'armless': 0.0,\n",
       " 'bone-covered': -0.125,\n",
       " 'scaly': 0.0,\n",
       " 'silver-scaled': 0.0,\n",
       " 'scaleless': -0.625,\n",
       " 'artful': 0.625,\n",
       " 'crafty': 0.5,\n",
       " 'cute': 0.625,\n",
       " 'designing': 0.125,\n",
       " 'deep': 0.625,\n",
       " 'elusive': 0.625,\n",
       " 'manipulative': 0.25,\n",
       " 'pawky': -0.125,\n",
       " 'artless': -0.375,\n",
       " 'careless': -0.125,\n",
       " 'articulate': -0.375,\n",
       " 'eloquent': 0.25,\n",
       " 'speech-endowed': 0.5,\n",
       " 'well-spoken': 0.0,\n",
       " 'inarticulate': -0.625,\n",
       " 'aphasic': -0.75,\n",
       " 'aphonic': -0.75,\n",
       " 'dumb': 0.0,\n",
       " 'incoherent': -0.375,\n",
       " 'mute': -0.25,\n",
       " 'speechless': -0.625,\n",
       " 'unarticulated': -0.5,\n",
       " 'speaking': 0.5,\n",
       " 'tongued': -0.25,\n",
       " 'nonspeaking': -0.5,\n",
       " 'articulated': -0.625,\n",
       " 'jointed': 0.0,\n",
       " 'unjointed': -0.5,\n",
       " 'ashamed': -0.75,\n",
       " 'discredited': -0.5,\n",
       " 'embarrassed': -0.5,\n",
       " 'guilty': 0.25,\n",
       " 'shamefaced': 0.25,\n",
       " 'unashamed': 0.0,\n",
       " 'shameless': -0.5,\n",
       " 'unabashed': -0.375,\n",
       " 'assertive': 0.375,\n",
       " 'cocky': 0.25,\n",
       " 'emphatic': 0.25,\n",
       " 'unassertive': 0.625,\n",
       " 'nonassertive': -0.125,\n",
       " 'reticent': -0.125,\n",
       " 'associative': -0.625,\n",
       " 'associable': 0.625,\n",
       " 'nonassociative': -0.125,\n",
       " 'attached': 0.0,\n",
       " 'bespoken': 0.25,\n",
       " 'intended': 0.0,\n",
       " 'involved': 0.0,\n",
       " 'unattached': -0.75,\n",
       " 'unengaged': -0.625,\n",
       " 'affixed': 0.125,\n",
       " 'appendant': 0.0,\n",
       " 'basifixed': 0.0,\n",
       " 'glued': 0.0,\n",
       " 'unaffixed': -0.25,\n",
       " 'sessile': -0.125,\n",
       " 'pedunculate': -0.125,\n",
       " 'vagile': 0.0,\n",
       " 'free-swimming': -0.125,\n",
       " 'detached': 0.0,\n",
       " 'freestanding': -0.5,\n",
       " 'semidetached': 0.0,\n",
       " 'stuck': 0.0,\n",
       " 'cragfast': 0.0,\n",
       " 'unstuck': 0.25,\n",
       " 'attachable': 0.5,\n",
       " 'bindable': 0.5,\n",
       " 'clip-on': 0.125,\n",
       " 'tie-on': 0.0,\n",
       " 'detachable': 0.25,\n",
       " 'clastic': 0.625,\n",
       " 'wary': 0.625,\n",
       " 'on_guard': 0.375,\n",
       " 'shy': 0.25,\n",
       " 'unwary': -0.5,\n",
       " 'gullible': 0.375,\n",
       " 'unguarded': -0.25,\n",
       " 'attentive': 0.25,\n",
       " 'captive': 0.125,\n",
       " 'advertent': 0.5,\n",
       " 'observant': 0.5,\n",
       " 'oversolicitous': -0.5,\n",
       " 'solicitous': 0.25,\n",
       " 'inattentive': -0.125,\n",
       " 'absent': 0.25,\n",
       " 'distracted': -0.25,\n",
       " 'dreamy': 0.0,\n",
       " 'drowsy': -0.125,\n",
       " 'forgetful': 0.375,\n",
       " 'attractive': 0.875,\n",
       " 'bewitching': 0.5,\n",
       " 'charismatic': 0.5,\n",
       " 'cunning': 0.5,\n",
       " 'dinky': 0.5,\n",
       " 'engaging': 0.875,\n",
       " 'fetching': 0.625,\n",
       " 'glossy': -0.375,\n",
       " 'hypnotic': 0.375,\n",
       " 'irresistible': 0.5,\n",
       " 'personable': 0.625,\n",
       " 'photogenic': 0.5,\n",
       " 'prepossessing': 0.5,\n",
       " 'winsome': 0.625,\n",
       " 'unattractive': 0.25,\n",
       " 'homely': 0.125,\n",
       " 'subfusc': -0.125,\n",
       " 'unprepossessing': -0.125,\n",
       " 'repulsive': 0.5,\n",
       " 'appealing': 0.25,\n",
       " 'attention-getting': 0.25,\n",
       " 'unappealing': -0.5,\n",
       " 'off-putting': -0.25,\n",
       " 'attributable': 0.625,\n",
       " 'ascribable': -0.25,\n",
       " 'credited': 0.0,\n",
       " 'traceable': 0.0,\n",
       " 'unattributable': -0.125,\n",
       " 'attributive': 0.0,\n",
       " 'attributive_genitive': 0.0,\n",
       " 'predicative': 0.0,\n",
       " 'pregnant': 0.0,\n",
       " 'big': 0.0,\n",
       " 'nonpregnant': -0.125,\n",
       " 'audible': 0.375,\n",
       " 'clunky': 0.0,\n",
       " 'sonic': 0.0,\n",
       " 'sounding': 0.0,\n",
       " 'inaudible': -0.375,\n",
       " 'breathed': 0.125,\n",
       " 'infrasonic': 0.375,\n",
       " 'silent': 0.0,\n",
       " 'supersonic': 0.375,\n",
       " 'unheard': 0.25,\n",
       " 'subsonic': 0.0,\n",
       " 'auspicious': 0.625,\n",
       " 'bright': -0.375,\n",
       " 'fortunate': 0.75,\n",
       " 'inauspicious': -0.778,\n",
       " 'unpromising': -0.375,\n",
       " 'propitious': 0.5,\n",
       " 'golden': 0.75,\n",
       " 'gracious': 0.375,\n",
       " 'unpropitious': -0.625,\n",
       " 'ill': -0.5,\n",
       " 'thunderous': -0.75,\n",
       " 'authorized': -0.375,\n",
       " 'accredited': 0.0,\n",
       " 'approved': 0.0,\n",
       " 'canonized': 0.0,\n",
       " 'empowered': 0.0,\n",
       " 'unauthorized': -0.875,\n",
       " 'self-appointed': 0.0,\n",
       " 'unaccredited': -0.25,\n",
       " 'constitutional': 0.0,\n",
       " 'unconstitutional': -0.75,\n",
       " 'autochthonous': 0.0,\n",
       " 'allochthonous': 0.0,\n",
       " 'autoecious': 0.0,\n",
       " 'heteroecious': 0.0,\n",
       " 'autogenous': 0.0,\n",
       " 'self-generated': 0.0,\n",
       " 'self-induced': -0.625,\n",
       " 'heterogenous': 0.0,\n",
       " 'automatic': 0.0,\n",
       " 'autoloading': 0.375,\n",
       " 'automated': 0.0,\n",
       " 'self-acting': 0.0,\n",
       " 'self-locking': 0.0,\n",
       " 'self-winding': 0.0,\n",
       " 'semiautomatic': 0.0,\n",
       " 'smart': 0.5,\n",
       " 'manual': -0.25,\n",
       " 'hand-operated': 0.0,\n",
       " 'available': 0.375,\n",
       " 'acquirable': 0.625,\n",
       " 'addressable': 0.625,\n",
       " 'forthcoming': 0.125,\n",
       " 'gettable': 0.625,\n",
       " 'in_stock': 0.0,\n",
       " 'lendable': 0.25,\n",
       " 'visible': 0.375,\n",
       " 'on_hand': 0.375,\n",
       " 'on_tap': 0.0,\n",
       " 'purchasable': 0.0,\n",
       " 'ready': 0.0,\n",
       " 'unavailable': -0.125,\n",
       " 'out_of_stock': -0.625,\n",
       " 'awake': -0.375,\n",
       " 'astir': 0.0,\n",
       " 'awakened': 0.0,\n",
       " 'insomniac': -0.625,\n",
       " 'unsleeping': -0.25,\n",
       " 'waking': 0.0,\n",
       " 'at_rest': 0.0,\n",
       " 'fast_asleep': -0.125,\n",
       " 'hypnoid': 0.0,\n",
       " 'sleepy': 0.0,\n",
       " 'slumberous': 0.375,\n",
       " 'unawakened': -0.25,\n",
       " 'astringent': -0.125,\n",
       " 'styptic': -0.25,\n",
       " 'nonastringent': -0.375,\n",
       " 'aware': 0.5,\n",
       " 'conscious': 0.625,\n",
       " 'sensible': 0.625,\n",
       " 'unaware': -0.25,\n",
       " 'oblivious': -0.125,\n",
       " 'unconscious': -0.75,\n",
       " 'unsuspecting': -0.625,\n",
       " 'witting': 0.375,\n",
       " 'unwitting': -0.625,\n",
       " 'alarming': -0.5,\n",
       " 'appalling': -0.5,\n",
       " 'atrocious': -0.625,\n",
       " 'awful': -0.625,\n",
       " 'baleful': -0.75,\n",
       " 'bloodcurdling': -0.375,\n",
       " 'chilling': -0.75,\n",
       " 'creepy': -0.5,\n",
       " 'formidable': 0.625,\n",
       " 'ghastly': -0.375,\n",
       " 'hairy': -0.25,\n",
       " 'petrifying': -0.25,\n",
       " 'stupefying': 0.125,\n",
       " 'terrific': -0.625,\n",
       " 'unalarming': 0.0,\n",
       " 'anemophilous': 0.0,\n",
       " 'entomophilous': 0.0,\n",
       " 'reassuring': 0.5,\n",
       " 'assuasive': 0.25,\n",
       " 'assuring': 0.5,\n",
       " 'comforting': 0.0,\n",
       " 'unreassuring': -0.25,\n",
       " 'backmost': 0.0,\n",
       " 'rear': 0.0,\n",
       " 'front': 0.0,\n",
       " 'advance': 0.0,\n",
       " 'foremost': 0.0,\n",
       " 'leading': 0.375,\n",
       " 'directing': 0.0,\n",
       " 'guiding': 0.0,\n",
       " 'pursuing': 0.0,\n",
       " 'backed': 0.0,\n",
       " 'hardbacked': -0.125,\n",
       " 'high-backed': 0.125,\n",
       " 'low-backed': -0.125,\n",
       " 'razorback': 0.0,\n",
       " 'spiny-backed': -0.125,\n",
       " 'stiff-backed': 0.0,\n",
       " 'straight-backed': 0.0,\n",
       " 'backless': -0.25,\n",
       " 'low-cut': 0.0,\n",
       " 'backward': 0.0,\n",
       " 'backswept': 0.0,\n",
       " 'cacuminal': 0.0,\n",
       " 'converse': 0.0,\n",
       " 'inverse': 0.125,\n",
       " 'rearward': 0.0,\n",
       " 'receding': 0.0,\n",
       " 'reflexive': 0.0,\n",
       " 'regardant': 0.0,\n",
       " 'retracted': 0.0,\n",
       " ...}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f68a5fa-ec0a-4e05-b000-9d7963b32ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNWithLexicon(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes, lexicon_dim=1, kernel_sizes=[3, 4, 5], num_filters=100):\n",
    "        super(CNNWithLexicon, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Convolutional layers for text\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (k, embedding_dim + lexicon_dim))\n",
    "            for k in kernel_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, tokens, lexicon_features):\n",
    "        # Word embeddings\n",
    "        embed = self.embedding(tokens)  # [batch_size, seq_len, embedding_dim]\n",
    "        \n",
    "        # Combine word embeddings with lexicon features\n",
    "        lexicon_features = lexicon_features.unsqueeze(-1)  # [batch_size, seq_len, 1]\n",
    "        combined = torch.cat((embed, lexicon_features), dim=-1)  # [batch_size, seq_len, embedding_dim + lexicon_dim]\n",
    "        \n",
    "        # Add a channel dimension for CNN\n",
    "        combined = combined.unsqueeze(1)  # [batch_size, 1, seq_len, embedding_dim + lexicon_dim]\n",
    "        \n",
    "        # Convolution and pooling\n",
    "        conv_outputs = [\n",
    "            torch.relu(conv(combined)).squeeze(3) for conv in self.convs\n",
    "        ]  # List of [batch_size, num_filters, seq_len - kernel_size + 1]\n",
    "        pooled_outputs = [torch.max(conv, dim=2)[0] for conv in conv_outputs]  # [batch_size, num_filters]\n",
    "        \n",
    "        # Concatenate and classify\n",
    "        concatenated = torch.cat(pooled_outputs, dim=1)  # [batch_size, len(kernel_sizes) * num_filters]\n",
    "        dropped = self.dropout(concatenated)\n",
    "        output = self.fc(dropped)  # [batch_size, num_classes]\n",
    "        return self.softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b9edaf0-9968-43c3-9e34-c5cdaca79a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 40000\n",
      "Testing samples: 10000\n",
      "Model Outputs: tensor([[0.3235, 0.6765],\n",
      "        [0.1042, 0.8958],\n",
      "        [0.3507, 0.6493],\n",
      "        [0.4043, 0.5957],\n",
      "        [0.1861, 0.8139],\n",
      "        [0.3174, 0.6826],\n",
      "        [0.5031, 0.4969],\n",
      "        [0.4350, 0.5650],\n",
      "        [0.6352, 0.3648],\n",
      "        [0.2937, 0.7063],\n",
      "        [0.7657, 0.2343],\n",
      "        [0.9307, 0.0693],\n",
      "        [0.9252, 0.0748],\n",
      "        [0.5533, 0.4467],\n",
      "        [0.4714, 0.5286],\n",
      "        [0.5683, 0.4317],\n",
      "        [0.2497, 0.7503],\n",
      "        [0.6957, 0.3043],\n",
      "        [0.3937, 0.6063],\n",
      "        [0.1394, 0.8606],\n",
      "        [0.3118, 0.6882],\n",
      "        [0.3103, 0.6897],\n",
      "        [0.4219, 0.5781],\n",
      "        [0.4100, 0.5900],\n",
      "        [0.3278, 0.6722],\n",
      "        [0.3143, 0.6857],\n",
      "        [0.4965, 0.5035],\n",
      "        [0.5376, 0.4624],\n",
      "        [0.7980, 0.2020],\n",
      "        [0.7103, 0.2897],\n",
      "        [0.7137, 0.2863],\n",
      "        [0.1026, 0.8974]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Split the Dataset\n",
    "train_split = 0.8\n",
    "train_size = int(train_split * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Display split information\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Testing samples: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "# Create model\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "num_classes = 2\n",
    "\n",
    "model = CNNWithLexicon(vocab_size, embedding_dim, num_classes)\n",
    "sample_batch = next(iter(train_loader))\n",
    "tokens = sample_batch['tokens']\n",
    "lexicon_features = sample_batch['lexicon_features']\n",
    "outputs = model(tokens, lexicon_features)\n",
    "\n",
    "print(\"Model Outputs:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86bdc67-1f46-40c9-9e5a-5651ab0fb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            tokens = batch['tokens']\n",
    "            lexicon_features = batch['lexicon_features']\n",
    "            labels = batch['label']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(tokens, lexicon_features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "# Training example\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3a7e7-588c-4e1e-8e97-7f3dbfa18a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lign167)",
   "language": "python",
   "name": "lign167"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
